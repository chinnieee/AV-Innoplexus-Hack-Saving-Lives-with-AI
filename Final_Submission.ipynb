{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](in.jpg)\n",
    "# Innoplexus Online Hiring Hackathon: Saving lives with AI\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Clinical studies often require detailed patientsâ€™ information documented in clinical narratives. **Named Entity Recognition (NER) is a fundamental Natural Language Processing (NLP) task to extract entities of interest (e.g., disease names, medication names and lab tests) from clinical narratives, thus to support clinical and translational research.** Clinical notes have been analyzed in greater detail to harness important information for clinical research and other healthcare operations, as they depict rich, detailed medical information.\n",
    "\n",
    "\n",
    "In this challenge, hackers are invited to extract all disease names from a given set of 20000 paragraphs/documents in the test set provided the labelled entities (diseases) for 30000 documents in the train set.\n",
    "\n",
    "For example, here is a sentence from a clinical report:\n",
    "\n",
    "*We compared the inter-day reproducibility of post-occlusive **reactive hyperemia** (PORH) assessed by single-point laser Doppler flowmetry (LDF) and laser speckle contrast analysis (LSCI).*\n",
    "\n",
    "\n",
    "In the sentence given, **reactive hyperemia (in bold)** is the named entity with the type disease/indication.\n",
    "\n",
    " \n",
    "\n",
    "## Data Description\n",
    "The train file has the following structure:\n",
    " \n",
    "|Variable | Definition|\n",
    "|---|---|\n",
    "|id|\tUnique ID for a token/word|\n",
    "|Doc_ID\t|Unique ID for a Document/Paragraph|\n",
    "|Sent_ID|\tUnique ID for a Sentence|\n",
    "|Word\t|Exact word/token|\n",
    "|tag\t(Target)| Named Entity Tag  |\n",
    "\n",
    "The target 'tag' follows the **Inside-outside-beginning (IOB)** tagging format. The IOB format (short for inside, outside, beginning) is a common tagging format for tagging tokens in named-entity recognition.\n",
    "\n",
    "**The B-indications (beginning) tag indicates that the token is the beginning of a disease entity (disease name in this case)\n",
    "An I-indications (inside) tag indicates that the token is inside an entity\n",
    "An O (outside) tag indicates that a token is outside a disease entity**\n",
    " \n",
    "**Example**\n",
    "For more clarity, let's look at the same sample in the given tabular format, each row here corresponds to a word/token:\n",
    "\n",
    "The disease **'reactive hyperemia'** is labelled using **'B-indications'** for the word **'reactive'** and **'I-indications'** for the word **'hypermia'**. All the other words that are outside **'reactive hyperemia'** are labelled with **'O'.**\n",
    "\n",
    "\n",
    "## Evaluation Metric\n",
    "\n",
    "The evaluation for this contest is based on modified F1-Score as explained below:\n",
    "Suppose the ground truth has the following entities (mentioned in square brackets) for the given sentence\n",
    "\n",
    "**[Malaria] and [Yellow Fever] remain more deadly than [Hepatitis B] today**\n",
    "\n",
    "This has 3 entities.\n",
    "Supposing the actual prediction has the following\n",
    "\n",
    "**[Malaria] [and] [Yellow] Fever remain more deadly than Hepatitis B [today]**\n",
    "\n",
    "We have an exact match for Malaria, false positives for and and today, a false negative for Hepatitis B and a substring match for Yellow. We compute precision and recall by first defining matching criteria. We are also trying to reward partial match here and not just exact entity match.\n",
    "\n",
    "Here, True positives are of 2 types - Exact match and partial match and we are giving a weight of 1 to Exact Match and 0.5 to partial match. The computations are as follows:\n",
    "\n",
    "Exact Match = 1 (Malaria) and Partial Match = 1 ( Yellow which overlaps Yellow Fever), False Positives =2 (and, and today), False Negatives = 1 (Hepatitis B)\n",
    "\n",
    "**Precision** = (Exact Match + 0.5 * Partial Match) / (Exact Match + Partial Match + False Positives) = (1 + 0.5)/(1+1+2) = 0.375\n",
    "\n",
    "**Recall** = (Exact Match + 0.5 * Partial Match) / (Exact Match + Partial Match + False Negatives) = (1 + 0.5)/(1+1+1) = 0.50\n",
    "\n",
    "**F1 Score** = (2 * Precision * Recall)/(Precision + Recall) = 0.428\n",
    "\n",
    "\n",
    "The counts of exact match, partial match, false positives and false negatives is summed across all sentences in the test set and overall F1 Score is the leaderboard score.\n",
    "\n",
    "Please find the script for the evaluation metric implemented in Python at this [link](https://gist.github.com/frenzy2106/3a12b7fefeb33941edea45d881d6f81a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle-Income</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Doc_ID  Sent_ID           Word tag\n",
       "0   1       1        1        Obesity   O\n",
       "1   2       1        1             in   O\n",
       "2   3       1        1           Low-   O\n",
       "3   4       1        1            and   O\n",
       "4   5       1        1  Middle-Income   O"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "s=pd.read_csv('sample_submission.csv')\n",
    "\n",
    "\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainiob=pd.read_csv('train_treeiob.csv')\n",
    "\n",
    "testiob=pd.read_csv('test_treeiob.csv')\n",
    "\n",
    "trainpos=pd.read_csv('train_pos.csv')\n",
    "testpos=pd.read_csv('test_pos.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>tag</th>\n",
       "      <th>pos</th>\n",
       "      <th>tree_iob</th>\n",
       "      <th>pred_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>O</td>\n",
       "      <td>NN</td>\n",
       "      <td>B</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low-</td>\n",
       "      <td>O</td>\n",
       "      <td>NNP</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle-Income</td>\n",
       "      <td>O</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Doc_ID  Sent_ID           Word tag  pos tree_iob pred_tag\n",
       "0   1       1        1        Obesity   O   NN        B        O\n",
       "1   2       1        1             in   O   IN        O        O\n",
       "2   3       1        1           Low-   O  NNP        O        O\n",
       "3   4       1        1            and   O   CC        O        O\n",
       "4   5       1        1  Middle-Income   O   JJ        O        O"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['pos']=trainpos['pos']\n",
    "train['tree_iob']=trainiob['tree_iob']\n",
    "\n",
    "\n",
    "test['pos']=testpos['pos']\n",
    "test['tree_iob']=testiob['tree_iob']\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df=train.copy()\n",
    "dftest=test.copy()\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(v):\n",
    "    v=str(v)\n",
    "    r=''\n",
    "    \n",
    "    if len(v)!=1 and (v[-1]=='.' or v.find(':')!=-1 or v.find(\"'\")!=-1 or v.find(\",\")!=-1):\n",
    "        r=re.sub(r'[^\\w\\s]','',v)\n",
    "    else:\n",
    "        r=v\n",
    "    if r=='':\n",
    "        return ','\n",
    "    return r\n",
    "    \n",
    "df['Word']=df['Word'].apply(clean)\n",
    "dftest['Word']=dftest['Word'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>tag</th>\n",
       "      <th>pos</th>\n",
       "      <th>tree_iob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>O</td>\n",
       "      <td>NN</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low-</td>\n",
       "      <td>O</td>\n",
       "      <td>NNP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle-Income</td>\n",
       "      <td>O</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Doc_ID  Sent_ID           Word tag  pos tree_iob\n",
       "0   1       1        1        Obesity   O   NN        B\n",
       "1   2       1        1             in   O   IN        O\n",
       "2   3       1        1           Low-   O  NNP        O\n",
       "3   4       1        1            and   O   CC        O\n",
       "4   5       1        1  Middle-Income   O   JJ        O"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "st=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>tag</th>\n",
       "      <th>pos</th>\n",
       "      <th>tree_iob</th>\n",
       "      <th>pred_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>O</td>\n",
       "      <td>NN</td>\n",
       "      <td>B</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low-</td>\n",
       "      <td>O</td>\n",
       "      <td>NNP</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle-Income</td>\n",
       "      <td>O</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Doc_ID  Sent_ID           Word tag  pos tree_iob pred_tag\n",
       "0   1       1        1        Obesity   O   NN        B        O\n",
       "1   2       1        1             in   O   IN        O        O\n",
       "2   3       1        1           Low-   O  NNP        O        O\n",
       "3   4       1        1            and   O   CC        O        O\n",
       "4   5       1        1  Middle-Income   O   JJ        O        O"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w,p,e, t) for w,p,e, t in zip(s['Word'].astype(str).values.tolist(), \n",
    "                                                       s['pos'].astype(str).values.tolist(), s['tree_iob'].values.tolist(),\n",
    "                                                           s['tag'].values.tolist())]\n",
    "        self.grouped = self.data.groupby(['Doc_ID','Sent_ID']).apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None\n",
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    tr_iob = sent[i][2]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.isidentifier()':word.isidentifier(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2], \n",
    "        'tree_iob':tr_iob,\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        tr_iob1 = sent[i-1][2]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "            '-1:tree_iob':tr_iob1,\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        tr_iob1=sent[i+1][2]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "            '+1:tree_iob':tr_iob1,\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag,tiob, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag,tiob, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "X = [sent2features(s) for s in tqdm(sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [sent2labels(s) for s in tqdm(sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction import DictVectorizer\n",
    "# from sklearn.feature_extraction.text import HashingVectorizer\n",
    "# from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:600], y[:600], test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Acer\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing and Evaluating Model\n",
    "\n",
    "For only 600 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 450/450 [00:01<00:00, 237.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 10688\n",
      "Seconds required: 0.100\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.001000\n",
      "c2: 0.001000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.01  loss=1310.92  active=10663 feature_norm=1.00\n",
      "Iter 2   time=0.01  loss=1221.20  active=10594 feature_norm=1.07\n",
      "Iter 3   time=0.01  loss=1083.03  active=10530 feature_norm=1.23\n",
      "Iter 4   time=0.01  loss=1034.19  active=10614 feature_norm=1.34\n",
      "Iter 5   time=0.01  loss=979.07   active=10629 feature_norm=1.48\n",
      "Iter 6   time=0.01  loss=873.32   active=10644 feature_norm=1.64\n",
      "Iter 7   time=0.01  loss=647.20   active=10647 feature_norm=3.23\n",
      "Iter 8   time=0.01  loss=586.06   active=10679 feature_norm=3.73\n",
      "Iter 9   time=0.01  loss=572.11   active=10668 feature_norm=4.73\n",
      "Iter 10  time=0.01  loss=517.28   active=10676 feature_norm=4.73\n",
      "Iter 11  time=0.01  loss=497.37   active=10681 feature_norm=5.03\n",
      "Iter 12  time=0.01  loss=448.13   active=10674 feature_norm=5.97\n",
      "Iter 13  time=0.01  loss=382.20   active=10668 feature_norm=7.95\n",
      "Iter 14  time=0.01  loss=343.50   active=10672 feature_norm=10.01\n",
      "Iter 15  time=0.01  loss=321.15   active=10674 feature_norm=10.21\n",
      "Iter 16  time=0.01  loss=300.99   active=10671 feature_norm=10.95\n",
      "Iter 17  time=0.01  loss=231.71   active=10613 feature_norm=15.55\n",
      "Iter 18  time=0.01  loss=203.09   active=10070 feature_norm=16.21\n",
      "Iter 19  time=0.01  loss=167.76   active=9876  feature_norm=18.14\n",
      "Iter 20  time=0.01  loss=139.67   active=9469  feature_norm=21.27\n",
      "Iter 21  time=0.01  loss=110.27   active=8960  feature_norm=22.36\n",
      "Iter 22  time=0.01  loss=83.59    active=8899  feature_norm=25.00\n",
      "Iter 23  time=0.01  loss=58.60    active=8867  feature_norm=28.90\n",
      "Iter 24  time=0.01  loss=44.17    active=8857  feature_norm=33.29\n",
      "Iter 25  time=0.01  loss=35.11    active=8854  feature_norm=35.77\n",
      "Iter 26  time=0.01  loss=24.95    active=8824  feature_norm=40.62\n",
      "Iter 27  time=0.01  loss=18.76    active=8039  feature_norm=44.95\n",
      "Iter 28  time=0.01  loss=14.30    active=7903  feature_norm=46.81\n",
      "Iter 29  time=0.01  loss=11.31    active=7798  feature_norm=49.30\n",
      "Iter 30  time=0.01  loss=9.45     active=7608  feature_norm=51.93\n",
      "Iter 31  time=0.01  loss=8.27     active=7556  feature_norm=53.09\n",
      "Iter 32  time=0.01  loss=7.45     active=7523  feature_norm=54.53\n",
      "Iter 33  time=0.01  loss=6.97     active=7262  feature_norm=55.65\n",
      "Iter 34  time=0.01  loss=6.62     active=7201  feature_norm=55.72\n",
      "Iter 35  time=0.01  loss=6.41     active=7023  feature_norm=56.00\n",
      "Iter 36  time=0.01  loss=6.29     active=6830  feature_norm=56.34\n",
      "Iter 37  time=0.01  loss=6.19     active=6697  feature_norm=56.20\n",
      "Iter 38  time=0.01  loss=6.08     active=6558  feature_norm=56.09\n",
      "Iter 39  time=0.01  loss=5.95     active=6206  feature_norm=55.68\n",
      "Iter 40  time=0.02  loss=5.92     active=5797  feature_norm=55.27\n",
      "Iter 41  time=0.01  loss=5.82     active=5672  feature_norm=55.11\n",
      "Iter 42  time=0.01  loss=5.77     active=5403  feature_norm=54.88\n",
      "Iter 43  time=0.01  loss=5.70     active=4935  feature_norm=54.40\n",
      "Iter 44  time=0.01  loss=5.64     active=4517  feature_norm=54.18\n",
      "Iter 45  time=0.01  loss=5.59     active=4215  feature_norm=53.97\n",
      "Iter 46  time=0.01  loss=5.55     active=3648  feature_norm=53.81\n",
      "Iter 47  time=0.01  loss=5.51     active=3277  feature_norm=53.66\n",
      "Iter 48  time=0.01  loss=5.47     active=3127  feature_norm=53.51\n",
      "Iter 49  time=0.01  loss=5.44     active=3026  feature_norm=53.41\n",
      "Iter 50  time=0.01  loss=5.42     active=2928  feature_norm=53.35\n",
      "Iter 51  time=0.01  loss=5.38     active=2741  feature_norm=53.13\n",
      "Iter 52  time=0.01  loss=5.34     active=2581  feature_norm=53.13\n",
      "Iter 53  time=0.01  loss=5.30     active=2441  feature_norm=52.86\n",
      "Iter 54  time=0.01  loss=5.28     active=2351  feature_norm=52.80\n",
      "Iter 55  time=0.01  loss=5.24     active=2231  feature_norm=52.59\n",
      "Iter 56  time=0.01  loss=5.21     active=2032  feature_norm=52.44\n",
      "Iter 57  time=0.01  loss=5.17     active=1906  feature_norm=52.12\n",
      "Iter 58  time=0.01  loss=5.15     active=1824  feature_norm=52.10\n",
      "Iter 59  time=0.01  loss=5.13     active=1786  feature_norm=51.99\n",
      "Iter 60  time=0.01  loss=5.11     active=1733  feature_norm=51.94\n",
      "Iter 61  time=0.01  loss=5.10     active=1691  feature_norm=51.86\n",
      "Iter 62  time=0.01  loss=5.09     active=1677  feature_norm=51.86\n",
      "Iter 63  time=0.01  loss=5.08     active=1672  feature_norm=51.87\n",
      "Iter 64  time=0.01  loss=5.06     active=1650  feature_norm=51.88\n",
      "Iter 65  time=0.01  loss=5.05     active=1643  feature_norm=51.86\n",
      "Iter 66  time=0.01  loss=5.04     active=1631  feature_norm=51.89\n",
      "Iter 67  time=0.01  loss=5.03     active=1621  feature_norm=51.87\n",
      "Iter 68  time=0.01  loss=5.03     active=1622  feature_norm=51.92\n",
      "Iter 69  time=0.01  loss=5.02     active=1614  feature_norm=51.85\n",
      "Iter 70  time=0.01  loss=5.01     active=1601  feature_norm=51.89\n",
      "Iter 71  time=0.01  loss=5.00     active=1594  feature_norm=51.86\n",
      "Iter 72  time=0.01  loss=5.00     active=1588  feature_norm=51.87\n",
      "Iter 73  time=0.01  loss=4.99     active=1585  feature_norm=51.84\n",
      "Iter 74  time=0.01  loss=4.99     active=1578  feature_norm=51.86\n",
      "Iter 75  time=0.01  loss=4.98     active=1573  feature_norm=51.83\n",
      "Iter 76  time=0.01  loss=4.98     active=1568  feature_norm=51.85\n",
      "Iter 77  time=0.01  loss=4.97     active=1558  feature_norm=51.82\n",
      "Iter 78  time=0.01  loss=4.97     active=1554  feature_norm=51.86\n",
      "Iter 79  time=0.01  loss=4.97     active=1554  feature_norm=51.84\n",
      "Iter 80  time=0.01  loss=4.96     active=1542  feature_norm=51.87\n",
      "Iter 81  time=0.01  loss=4.96     active=1536  feature_norm=51.84\n",
      "Iter 82  time=0.01  loss=4.96     active=1536  feature_norm=51.88\n",
      "Iter 83  time=0.01  loss=4.95     active=1530  feature_norm=51.84\n",
      "Iter 84  time=0.01  loss=4.95     active=1527  feature_norm=51.87\n",
      "Iter 85  time=0.01  loss=4.95     active=1524  feature_norm=51.83\n",
      "Iter 86  time=0.01  loss=4.94     active=1513  feature_norm=51.85\n",
      "Iter 87  time=0.01  loss=4.94     active=1513  feature_norm=51.80\n",
      "Iter 88  time=0.01  loss=4.94     active=1504  feature_norm=51.83\n",
      "Iter 89  time=0.01  loss=4.93     active=1497  feature_norm=51.78\n",
      "Iter 90  time=0.01  loss=4.93     active=1495  feature_norm=51.81\n",
      "Iter 91  time=0.01  loss=4.93     active=1494  feature_norm=51.75\n",
      "Iter 92  time=0.01  loss=4.93     active=1490  feature_norm=51.77\n",
      "Iter 93  time=0.01  loss=4.92     active=1492  feature_norm=51.72\n",
      "Iter 94  time=0.01  loss=4.92     active=1486  feature_norm=51.75\n",
      "Iter 95  time=0.01  loss=4.92     active=1482  feature_norm=51.70\n",
      "Iter 96  time=0.01  loss=4.91     active=1470  feature_norm=51.72\n",
      "Iter 97  time=0.01  loss=4.91     active=1469  feature_norm=51.67\n",
      "Iter 98  time=0.01  loss=4.91     active=1464  feature_norm=51.69\n",
      "Iter 99  time=0.01  loss=4.91     active=1461  feature_norm=51.65\n",
      "Iter 100 time=0.01  loss=4.91     active=1459  feature_norm=51.67\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 0.934\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 1459 (10688)\n",
      "Number of active attributes: 1018 (10231)\n",
      "Number of active labels: 3 (3)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.078\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.001,\n",
       "  c2=0.001, calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.001,\n",
    "    c2=0.001,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True,verbose=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = list(crf.classes_)\n",
    "# labels.remove('O')\n",
    "labels=['B-indications','I-indications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-indications', 'I-indications']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "B-indications       0.75      0.42      0.54        43\n",
      "I-indications       0.76      0.34      0.47        38\n",
      "\n",
      "  avg / total       0.76      0.38      0.51        81\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5070137527848971"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels = labels))\n",
    "metrics.flat_f1_score(y_test, y_pred,average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 191282/191282 [09:53<00:00, 322.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 519782\n",
      "Seconds required: 65.979\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.010000\n",
      "c2: 0.010000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=5.92  loss=660781.26 active=518830 feature_norm=1.00\n",
      "Iter 2   time=3.19  loss=598779.72 active=515207 feature_norm=1.09\n",
      "Iter 3   time=2.94  loss=541180.97 active=512454 feature_norm=1.26\n",
      "Iter 4   time=2.80  loss=526749.81 active=516050 feature_norm=1.34\n",
      "Iter 5   time=3.02  loss=517387.72 active=516786 feature_norm=1.42\n",
      "Iter 6   time=2.96  loss=499076.29 active=517174 feature_norm=1.46\n",
      "Iter 7   time=2.74  loss=303384.84 active=516533 feature_norm=5.88\n",
      "Iter 8   time=6.34  loss=288576.05 active=517030 feature_norm=6.90\n",
      "Iter 9   time=2.75  loss=284301.19 active=517161 feature_norm=7.24\n",
      "Iter 10  time=2.76  loss=266323.36 active=517304 feature_norm=7.95\n",
      "Iter 11  time=2.76  loss=259680.23 active=517138 feature_norm=8.62\n",
      "Iter 12  time=2.74  loss=244670.23 active=517294 feature_norm=9.98\n",
      "Iter 13  time=2.96  loss=242962.55 active=516096 feature_norm=12.95\n",
      "Iter 14  time=2.93  loss=225919.70 active=516053 feature_norm=13.28\n",
      "Iter 15  time=3.01  loss=221405.55 active=515664 feature_norm=14.30\n",
      "Iter 16  time=2.90  loss=216486.36 active=514180 feature_norm=17.26\n",
      "Iter 17  time=3.16  loss=211815.26 active=514124 feature_norm=17.55\n",
      "Iter 18  time=2.85  loss=208933.59 active=513659 feature_norm=17.82\n",
      "Iter 19  time=2.73  loss=197140.47 active=511026 feature_norm=19.63\n",
      "Iter 20  time=2.73  loss=187509.11 active=505456 feature_norm=20.40\n",
      "Iter 21  time=2.81  loss=179357.22 active=441837 feature_norm=22.66\n",
      "Iter 22  time=2.78  loss=173118.03 active=426227 feature_norm=23.86\n",
      "Iter 23  time=2.95  loss=165711.84 active=401454 feature_norm=26.52\n",
      "Iter 24  time=2.79  loss=156707.22 active=383478 feature_norm=30.28\n",
      "Iter 25  time=2.75  loss=148702.48 active=365801 feature_norm=35.97\n",
      "Iter 26  time=2.74  loss=143267.68 active=358828 feature_norm=39.30\n",
      "Iter 27  time=2.73  loss=134984.20 active=346161 feature_norm=46.61\n",
      "Iter 28  time=2.73  loss=128982.08 active=345344 feature_norm=51.52\n",
      "Iter 29  time=2.73  loss=122254.03 active=339689 feature_norm=59.28\n",
      "Iter 30  time=2.73  loss=115128.10 active=335138 feature_norm=68.32\n",
      "Iter 31  time=2.75  loss=107882.68 active=324811 feature_norm=80.79\n",
      "Iter 32  time=2.74  loss=101777.73 active=317605 feature_norm=91.99\n",
      "Iter 33  time=2.73  loss=94858.18 active=309473 feature_norm=111.12\n",
      "Iter 34  time=2.97  loss=88946.59 active=294919 feature_norm=128.00\n",
      "Iter 35  time=2.73  loss=82228.31 active=285238 feature_norm=154.31\n",
      "Iter 36  time=3.04  loss=76726.87 active=262098 feature_norm=177.14\n",
      "Iter 37  time=2.94  loss=71145.29 active=255431 feature_norm=209.56\n",
      "Iter 38  time=2.74  loss=66917.65 active=240445 feature_norm=233.51\n",
      "Iter 39  time=2.75  loss=62092.21 active=219782 feature_norm=268.86\n",
      "Iter 40  time=2.73  loss=58031.12 active=218277 feature_norm=298.54\n",
      "Iter 41  time=2.73  loss=53959.26 active=215907 feature_norm=336.47\n",
      "Iter 42  time=2.74  loss=51001.55 active=206186 feature_norm=361.26\n",
      "Iter 43  time=2.74  loss=47988.92 active=201861 feature_norm=392.64\n",
      "Iter 44  time=2.75  loss=45745.15 active=197209 feature_norm=412.08\n",
      "Iter 45  time=2.75  loss=43705.38 active=185954 feature_norm=436.89\n",
      "Iter 46  time=2.75  loss=42251.94 active=185759 feature_norm=450.89\n",
      "Iter 47  time=2.73  loss=40944.80 active=168343 feature_norm=468.03\n",
      "Iter 48  time=2.96  loss=39971.97 active=168417 feature_norm=478.40\n",
      "Iter 49  time=2.86  loss=39029.92 active=167672 feature_norm=491.46\n",
      "Iter 50  time=2.75  loss=38389.07 active=158046 feature_norm=498.97\n",
      "Iter 51  time=2.74  loss=37894.23 active=143385 feature_norm=505.47\n",
      "Iter 52  time=2.73  loss=37375.35 active=143207 feature_norm=507.23\n",
      "Iter 53  time=2.72  loss=36812.20 active=137011 feature_norm=512.04\n",
      "Iter 54  time=2.73  loss=36420.20 active=137661 feature_norm=513.43\n",
      "Iter 55  time=2.74  loss=36008.13 active=128281 feature_norm=517.93\n",
      "Iter 56  time=2.73  loss=35619.52 active=123025 feature_norm=521.32\n",
      "Iter 57  time=2.73  loss=35331.67 active=112822 feature_norm=525.56\n",
      "Iter 58  time=2.74  loss=35077.73 active=113502 feature_norm=527.41\n",
      "Iter 59  time=2.85  loss=34814.53 active=112679 feature_norm=530.59\n",
      "Iter 60  time=2.74  loss=34590.27 active=112048 feature_norm=532.50\n",
      "Iter 61  time=2.74  loss=34396.79 active=108209 feature_norm=534.99\n",
      "Iter 62  time=2.75  loss=34217.49 active=107853 feature_norm=536.46\n",
      "Iter 63  time=2.74  loss=34059.97 active=105892 feature_norm=538.50\n",
      "Iter 64  time=2.74  loss=33907.20 active=103230 feature_norm=539.85\n",
      "Iter 65  time=2.75  loss=33771.76 active=102708 feature_norm=541.74\n",
      "Iter 66  time=2.78  loss=33635.27 active=102833 feature_norm=542.97\n",
      "Iter 67  time=2.81  loss=33513.04 active=102290 feature_norm=544.46\n",
      "Iter 68  time=2.79  loss=33392.98 active=101380 feature_norm=545.42\n",
      "Iter 69  time=2.92  loss=33278.38 active=100458 feature_norm=546.93\n",
      "Iter 70  time=2.79  loss=33171.02 active=99735 feature_norm=547.82\n",
      "Iter 71  time=2.75  loss=33062.12 active=99117 feature_norm=549.12\n",
      "Iter 72  time=3.08  loss=32950.38 active=98455 feature_norm=550.17\n",
      "Iter 73  time=2.77  loss=32850.05 active=97907 feature_norm=551.54\n",
      "Iter 74  time=2.84  loss=32758.75 active=97758 feature_norm=552.49\n",
      "Iter 75  time=2.77  loss=32672.44 active=97044 feature_norm=553.72\n",
      "Iter 76  time=2.76  loss=32582.44 active=96650 feature_norm=554.84\n",
      "Iter 77  time=2.73  loss=32504.33 active=95688 feature_norm=556.28\n",
      "Iter 78  time=2.73  loss=32427.72 active=95260 feature_norm=557.17\n",
      "Iter 79  time=2.80  loss=32348.06 active=94543 feature_norm=558.35\n",
      "Iter 80  time=2.73  loss=32277.48 active=94037 feature_norm=559.36\n",
      "Iter 81  time=2.73  loss=32219.58 active=93538 feature_norm=560.25\n",
      "Iter 82  time=2.73  loss=32162.04 active=93330 feature_norm=560.88\n",
      "Iter 83  time=2.74  loss=32099.80 active=92714 feature_norm=561.72\n",
      "Iter 84  time=2.75  loss=32046.94 active=92454 feature_norm=562.41\n",
      "Iter 85  time=2.86  loss=31995.91 active=92038 feature_norm=563.19\n",
      "Iter 86  time=2.79  loss=31948.74 active=91929 feature_norm=563.75\n",
      "Iter 87  time=2.81  loss=31900.05 active=91495 feature_norm=564.52\n",
      "Iter 88  time=2.74  loss=31856.90 active=91410 feature_norm=565.12\n",
      "Iter 89  time=2.73  loss=31815.31 active=91181 feature_norm=565.75\n",
      "Iter 90  time=2.74  loss=31769.47 active=91173 feature_norm=566.25\n",
      "Iter 91  time=2.73  loss=31724.90 active=90714 feature_norm=567.03\n",
      "Iter 92  time=2.73  loss=31684.74 active=90634 feature_norm=567.54\n",
      "Iter 93  time=2.73  loss=31647.94 active=90375 feature_norm=568.09\n",
      "Iter 94  time=2.73  loss=31608.88 active=90248 feature_norm=568.61\n",
      "Iter 95  time=2.78  loss=31573.13 active=89847 feature_norm=569.30\n",
      "Iter 96  time=3.17  loss=31541.47 active=89821 feature_norm=569.79\n",
      "Iter 97  time=2.73  loss=31511.38 active=89588 feature_norm=570.30\n",
      "Iter 98  time=2.77  loss=31480.40 active=89561 feature_norm=570.77\n",
      "Iter 99  time=2.82  loss=31452.82 active=89225 feature_norm=571.51\n",
      "Iter 100 time=2.73  loss=31425.70 active=89252 feature_norm=572.02\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 286.900\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 89252 (519782)\n",
      "Number of active attributes: 67054 (496693)\n",
      "Number of active labels: 3 (3)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 1.195\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.01, c2=0.01,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.01,\n",
    "    c2=0.01,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True,verbose=True\n",
    ")\n",
    "crf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(crf,open('crf_model.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentenceGetterTest(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w,p,e) for w,p,e in zip(s['Word'].astype(str).values.tolist(), \n",
    "                                                       s['pos'].astype(str).values.tolist(), s['tree_iob'].values.tolist())]\n",
    "        self.grouped = self.data.groupby(['Doc_ID','Sent_ID']).apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None\n",
    "getter_test = SentenceGetterTest(dftest)\n",
    "test_sentences = getter_test.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = [sent2features(s) for s in tqdm(test_sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predtest = crf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2994463\n"
     ]
    }
   ],
   "source": [
    "z=[]\n",
    "for zz in y_predtest:\n",
    "    z.extend(zz)\n",
    "print(len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O                2935690\n",
       "B-indications      30975\n",
       "I-indications      27798\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=pd.read_csv('sample_submission.csv')\n",
    "s['tag']=z\n",
    "s['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.to_csv('s11_mainCRFft2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {
    "65076c48746542f194702979620d9ff1": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "7a473eeb96c840b5978da17e5a93a2e1": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "f3ffd571f02e4ce0b67f59bcb8b12b2c": {
     "views": [
      {
       "cell_index": 38
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
