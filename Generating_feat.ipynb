{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](in.jpg)\n",
    "# Innoplexus Online Hiring Hackathon: Saving lives with AI\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Clinical studies often require detailed patientsâ€™ information documented in clinical narratives. **Named Entity Recognition (NER) is a fundamental Natural Language Processing (NLP) task to extract entities of interest (e.g., disease names, medication names and lab tests) from clinical narratives, thus to support clinical and translational research.** Clinical notes have been analyzed in greater detail to harness important information for clinical research and other healthcare operations, as they depict rich, detailed medical information.\n",
    "\n",
    "\n",
    "In this challenge, hackers are invited to extract all disease names from a given set of 20000 paragraphs/documents in the test set provided the labelled entities (diseases) for 30000 documents in the train set.\n",
    "\n",
    "For example, here is a sentence from a clinical report:\n",
    "\n",
    "*We compared the inter-day reproducibility of post-occlusive **reactive hyperemia** (PORH) assessed by single-point laser Doppler flowmetry (LDF) and laser speckle contrast analysis (LSCI).*\n",
    "\n",
    "\n",
    "In the sentence given, **reactive hyperemia (in bold)** is the named entity with the type disease/indication.\n",
    "\n",
    " \n",
    "\n",
    "## Data Description\n",
    "The train file has the following structure:\n",
    " \n",
    "|Variable | Definition|\n",
    "|---|---|\n",
    "|id|\tUnique ID for a token/word|\n",
    "|Doc_ID\t|Unique ID for a Document/Paragraph|\n",
    "|Sent_ID|\tUnique ID for a Sentence|\n",
    "|Word\t|Exact word/token|\n",
    "|tag\t(Target)| Named Entity Tag  |\n",
    "\n",
    "The target 'tag' follows the **Inside-outside-beginning (IOB)** tagging format. The IOB format (short for inside, outside, beginning) is a common tagging format for tagging tokens in named-entity recognition.\n",
    "\n",
    "**The B-indications (beginning) tag indicates that the token is the beginning of a disease entity (disease name in this case)\n",
    "An I-indications (inside) tag indicates that the token is inside an entity\n",
    "An O (outside) tag indicates that a token is outside a disease entity**\n",
    " \n",
    "**Example**\n",
    "For more clarity, let's look at the same sample in the given tabular format, each row here corresponds to a word/token:\n",
    "\n",
    "The disease **'reactive hyperemia'** is labelled using **'B-indications'** for the word **'reactive'** and **'I-indications'** for the word **'hypermia'**. All the other words that are outside **'reactive hyperemia'** are labelled with **'O'.**\n",
    "\n",
    "\n",
    "## Evaluation Metric\n",
    "\n",
    "The evaluation for this contest is based on modified F1-Score as explained below:\n",
    "Suppose the ground truth has the following entities (mentioned in square brackets) for the given sentence\n",
    "\n",
    "**[Malaria] and [Yellow Fever] remain more deadly than [Hepatitis B] today**\n",
    "\n",
    "This has 3 entities.\n",
    "Supposing the actual prediction has the following\n",
    "\n",
    "**[Malaria] [and] [Yellow] Fever remain more deadly than Hepatitis B [today]**\n",
    "\n",
    "We have an exact match for Malaria, false positives for and and today, a false negative for Hepatitis B and a substring match for Yellow. We compute precision and recall by first defining matching criteria. We are also trying to reward partial match here and not just exact entity match.\n",
    "\n",
    "Here, True positives are of 2 types - Exact match and partial match and we are giving a weight of 1 to Exact Match and 0.5 to partial match. The computations are as follows:\n",
    "\n",
    "Exact Match = 1 (Malaria) and Partial Match = 1 ( Yellow which overlaps Yellow Fever), False Positives =2 (and, and today), False Negatives = 1 (Hepatitis B)\n",
    "\n",
    "**Precision** = (Exact Match + 0.5 * Partial Match) / (Exact Match + Partial Match + False Positives) = (1 + 0.5)/(1+1+2) = 0.375\n",
    "\n",
    "**Recall** = (Exact Match + 0.5 * Partial Match) / (Exact Match + Partial Match + False Negatives) = (1 + 0.5)/(1+1+1) = 0.50\n",
    "\n",
    "**F1 Score** = (2 * Precision * Recall)/(Precision + Recall) = 0.428\n",
    "\n",
    "\n",
    "The counts of exact match, partial match, false positives and false negatives is summed across all sentences in the test set and overall F1 Score is the leaderboard score.\n",
    "\n",
    "Please find the script for the evaluation metric implemented in Python at this [link](https://gist.github.com/frenzy2106/3a12b7fefeb33941edea45d881d6f81a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Obesity</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Low-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle-Income</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Doc_ID  Sent_ID           Word tag\n",
       "0   1       1        1        Obesity   O\n",
       "1   2       1        1             in   O\n",
       "2   3       1        1           Low-   O\n",
       "3   4       1        1            and   O\n",
       "4   5       1        1  Middle-Income   O"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "s=pd.read_csv('sample_submission.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4543834</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>CCCVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4543835</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4543836</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>MANOVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4543837</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4543838</td>\n",
       "      <td>30001</td>\n",
       "      <td>191283</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Doc_ID  Sent_ID    Word\n",
       "0  4543834   30001   191283   CCCVA\n",
       "1  4543835   30001   191283       ,\n",
       "2  4543836   30001   191283  MANOVA\n",
       "3  4543837   30001   191283       ,\n",
       "4  4543838   30001   191283      my"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sent_ID</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4543834</td>\n",
       "      <td>191283</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4543835</td>\n",
       "      <td>191283</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4543836</td>\n",
       "      <td>191283</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4543837</td>\n",
       "      <td>191283</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4543838</td>\n",
       "      <td>191283</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Sent_ID tag\n",
       "0  4543834   191283   O\n",
       "1  4543835   191283   O\n",
       "2  4543836   191283   O\n",
       "3  4543837   191283   O\n",
       "4  4543838   191283   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4543703, 5)\n"
     ]
    }
   ],
   "source": [
    "train.dropna(inplace=True)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df=train[train['Doc_ID']<=20000]\n",
    "df=train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O                4446076\n",
       "B-indications      53003\n",
       "I-indications      44624\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Word'].fillna('NA',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(v):\n",
    "    v=str(v)\n",
    "    r=''\n",
    "    \n",
    "    if len(v)!=1 and (v[-1]=='.' or v.find(':')!=-1 or v.find(\"'\")!=-1 or v.find(\",\")!=-1):\n",
    "        r=re.sub(r'[^\\w\\s]','',v)\n",
    "    else:\n",
    "        r=v\n",
    "    if r=='':\n",
    "        return ','\n",
    "    return r\n",
    "    \n",
    "df['Word']=df['Word'].apply(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Word']=test['Word'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4543703, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouping by Sent_ID and checking if the tokens formed are in unison with training rows**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting pos tagging from the tokens using nltk.pos_tag**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "agg_func = lambda s: \" \".join([w for w in s['Word'].values.tolist()])\n",
    "sentids=df.groupby(['Sent_ID']).apply(agg_func)\n",
    "post=[]\n",
    "for lll in sentids:\n",
    "    words = word_tokenize(lll)\n",
    "    if len(lll.split(\" \"))!=len(words):\n",
    "        print(lll)\n",
    "        print(words)\n",
    "        raise Exception('heheheh')\n",
    "    post.extend([q[1] for q in pos_tag(words)])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4543703"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test=pd.read_csv('test.csv')\n",
    "test['Word'].fillna('NA',inplace=True)\n",
    "test['Word']=test['Word'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "pos=[]\n",
    "tsentids=test.groupby(['Sent_ID']).apply(agg_func)\n",
    "for ll in tsentids:\n",
    "    \n",
    "    pos.extend([q[1] for q in pos_tag(word_tokenize(ll))])\n",
    "print(len(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(pos),test.shape)\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(pos),pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['pos']=post\n",
    "test['pos']=pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# post\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Generating conlltags with help of nltk.chunk and making another feature with  IOB tagging as 'O' / 'I' / 'B'**\n",
    "\n",
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "pos_iob=[]\n",
    "for lx in sentids:\n",
    "    words = word_tokenize(lx)\n",
    "    if len(lx.split(\" \"))!=len(words):\n",
    "#         print(i)\n",
    "        print(lll)\n",
    "        print(words)\n",
    "        raise Exception('heheheh')\n",
    "    pos_iob.extend([q[2][0] for q in tree2conlltags(ne_chunk(pos_tag(words)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(pos_iob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "# agg_func = lambda s: \" \".join([w for w in s['Word'].values.tolist()])\n",
    "# sentids=df.groupby(['Sent_ID']).apply(agg_func)\n",
    "post_iob=[]\n",
    "for lxx in tsentids:\n",
    "    words = word_tokenize(lxx)\n",
    "    if len(lxx.split(\" \"))!=len(words):\n",
    "#         print(i)\n",
    "        print(lxx)\n",
    "        print(words)\n",
    "        raise Exception('heheheh')\n",
    "    post_iob.extend([q[2][0] for q in tree2conlltags(ne_chunk(pos_tag(words)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tree_iob']=pos_iob\n",
    "test['tree_iob']=post_iob\n",
    "df['tree_iob'].to_csv('train_treeiob.csv',index=False)\n",
    "test['tree_iob'].to_csv('test_treeiob.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['tree_iob'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X\n",
    "df['pos'].to_csv('train_pos.csv',index=False)\n",
    "test['pos'].to_csv('test_pos.csv',index=False)\n",
    "# np.save('sent_X.npy',X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
